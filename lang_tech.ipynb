{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language technology final project\n",
        "##### Ilse Kerkhove, Marieke Schelhaas & Nikki van Gurp\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EeVe_hfVjQp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download nl_core_news_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B_8Bh7hFbYq",
        "outputId": "84c671b3-329a-47ee-aea3-5621a085766f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nl-core-news-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_lg-3.8.0/nl_core_news_lg-3.8.0-py3-none-any.whl (568.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.1/568.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nl-core-news-lg\n",
            "Successfully installed nl-core-news-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('nl_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xG7r4SU3hT23"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"nl_core_news_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "W6_xFy1yipQi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vinden van de mogelijke entity, de wiki id\n",
        "def get_entity(sentence):\n",
        "    url = 'https://www.wikidata.org/w/api.php'\n",
        "    headers = { 'User-Agent': 'nikkivgurp'}\n",
        "    params = {'action':'wbsearchentities',\n",
        "          'language':'nl',\n",
        "          'uselang':'nl',\n",
        "          'format':'json'}\n",
        "    if len(sentence.ents) != 0:\n",
        "        for ent in sentence.ents:\n",
        "            params['search'] = ent.text\n",
        "        try:\n",
        "          time.sleep(1) # To stop wiki_data from seeing me as a bot\n",
        "          result = requests.get(url,params).json()\n",
        "          return result['search'][0]['id']\n",
        "        except (KeyError, IndexError):\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# vinden van de mogelijke properties met Spacy\n",
        "def find_candidates(sentence):\n",
        "    sentence = nlp(question)\n",
        "    candidates = set()\n",
        "    for token in sentence:\n",
        "        # using dependency relations\n",
        "        if token.dep_ in (\"attr\", \"dobj\", \"popj\", \"nsubj\", \"ROOT\"):\n",
        "            candidates.add(token.lemma_)\n",
        "        elif token.pos_ == \"VERB\" and token.lemma_ != \"zijn\":\n",
        "            candidates.add(token.lemma_)\n",
        "    for chunk in sentence.noun_chunks:\n",
        "        candidates.add(chunk.root.text)\n",
        "        candidates.add(chunk.root.head.text)\n",
        "        candidates.add(chunk.lemma_)\n",
        "        candidates.add(chunk.text)\n",
        "    print(\"+++ \",candidates)\n",
        "    return candidates\n",
        "\n",
        "def get_property(candidates, entity_type):\n",
        "    url = 'https://www.wikidata.org/w/api.php'\n",
        "    params = {'action':'wbsearchentities',\n",
        "          'language':'nl',\n",
        "          'uselang':'nl',\n",
        "          'format':'json',\n",
        "          'type': entity_type}\n",
        "    if candidates:\n",
        "        properties = []\n",
        "        for candidate in candidates:\n",
        "            params['search'] = candidate\n",
        "            try:\n",
        "              time.sleep(1) # To stop wiki_data from seeing me as a bot\n",
        "              result = requests.get(url,params).json()\n",
        "              properties.append(result['search'][0]['id'])\n",
        "            except:\n",
        "                continue\n",
        "        return properties\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "# wikidata vinden met Sparql\n",
        "def get_wikidata(query):\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    headers = {'Accept': 'application/json', 'User-Agent': 'nikkivgurp'}\n",
        "    time.sleep(1) # To stop wiki_data from seeing me as a bot\n",
        "    results = requests.get(url, params={'query': query, 'format': 'json'}, headers=headers)\n",
        "    results.raise_for_status()\n",
        "    return results.json()\n",
        "\n",
        "# get all possible properties when given an entity\n",
        "def get_all_p(entity):\n",
        "  query = 'SELECT ?prop WHERE { wd:' + entity + ' ?prop ?val . FILTER STRSTARTS(STR(?prop), \"http://www.wikidata.org/prop/direct/P\")}'\n",
        "  wikidata = get_wikidata(query)\n",
        "  possible_p_values = set()\n",
        "  pattern = r'P\\d+'\n",
        "  for item in wikidata['results']['bindings']:\n",
        "        p_value = re.search(pattern, item['prop']['value'])\n",
        "        if p_value:\n",
        "          possible_p_values.add(p_value.group())\n",
        "  return possible_p_values\n",
        "\n",
        "\n",
        "# question answer functie\n",
        "def QA(question):\n",
        "    sentence = nlp(question)\n",
        "    properties = get_property(find_candidates(question), 'property')\n",
        "    entity = get_entity(sentence)\n",
        "    niksgevonden = False\n",
        "    yes_no_question = False\n",
        "\n",
        "    # checken of het een ja nee vraag is (vraag die start met werkwoord)\n",
        "    if sentence[0].pos_ == 'VERB' or sentence[0].pos_ =='AUX':\n",
        "      yes_no_question = True\n",
        "      extra_properties = get_property(find_candidates(question), 'item')\n",
        "      extra_properties.extend(properties)\n",
        "\n",
        "    answers = []\n",
        "    # Als het een ja of nee-vraag is\n",
        "    if yes_no_question:\n",
        "      if extra_properties and entity:\n",
        "        for prop in extra_properties:\n",
        "          try:\n",
        "              # simple yes no query\n",
        "              yes_no_query = 'ASK WHERE { wd:' + entity + ' wdt:' + prop + ' ?val. }'\n",
        "              response = get_wikidata(yes_no_query)\n",
        "              if response['boolean'] == True:\n",
        "                answers.append('Ja')\n",
        "                break\n",
        "          except:\n",
        "            continue\n",
        "        if len(answers) == 0:\n",
        "          question_prop = get_all_p(entity)\n",
        "          for prop in extra_properties:\n",
        "            for prop_q in question_prop:\n",
        "              try:\n",
        "                if len(answers) == 0:\n",
        "                  # more difficult yes no query\n",
        "                  yes_no_query = 'ASK WHERE { wd:' + entity + ' wdt:' + prop_q + ' wd:'  + prop + ' . }'\n",
        "                  response = get_wikidata(yes_no_query)\n",
        "                  if response['boolean'] == True:\n",
        "                    answers.append('Ja')\n",
        "                    break\n",
        "              except Exception as e:\n",
        "                # print('error', e)\n",
        "                continue\n",
        "        if len(answers) == 0:\n",
        "          answers.append('Nee')\n",
        "\n",
        "    # Overige vragen, waarin entity en property is ontdekt\n",
        "    elif properties and entity:\n",
        "        for prop in properties:\n",
        "            query = '''SELECT ?answer ?answerLabel WHERE {\n",
        "                       wd:''' + entity + ''' wdt:''' + prop + ''' ?answer .\n",
        "                       SERVICE wikibase:label {bd:serviceParam wikibase:language \"nl\" .\n",
        "                       }\n",
        "                      }'''\n",
        "            wikidata = get_wikidata(query)\n",
        "            bindings = wikidata.get('results', {}).get('bindings', [])\n",
        "            for result in bindings:\n",
        "                if 'answerLabel' in result:\n",
        "                    answers.append(result['answerLabel']['value'])\n",
        "\n",
        "    if len(answers) == 0:\n",
        "      niksgevonden = True\n",
        "      print(question, '\\t', 'Niks gevonden')\n",
        "    else:\n",
        "        print(question, '\\t', answers[-1])\n",
        "\n",
        "\n",
        "# Debugging Testsets\n",
        "## General Question-set\n",
        "q1 = 'Welke talen spreekt Arjen Lubach?'\n",
        "q2 = 'Wanneer is Jan Smit geboren?'\n",
        "q3 = 'Wanneer is Rembrandt van Rijn overleden?'\n",
        "q4 = 'Hoe heet het kind van Michiel de Ruyter?'\n",
        "question_list1 = [q1, q2, q3, q4]\n",
        "\n",
        "## Hoe Question-set\n",
        "q5 = 'Hoeveel volgers heeft Jan Smit?'\n",
        "q6 = 'Hoe oud is Mark Rutte?'\n",
        "q7 = 'Hoeveel onderscheidingen heeft Froukje?'\n",
        "q14 = 'Hoeveel kinderen heeft Dick Schoof?'\n",
        "question_list2 = [q5, q6, q7]\n",
        "\n",
        "## Lijst Question-set\n",
        "q8 = 'Welke talen spreek Arjen Lubach'\n",
        "q9 = '?'\n",
        "q10 = '?'\n",
        "question_list3 = [q8, q9, q10]\n",
        "\n",
        "## Ja/Nee Question-set\n",
        "q11 = '?'\n",
        "q12 = '?'\n",
        "q13 = '?'\n",
        "question_list4 = [q11, q12, q13]\n",
        "\n",
        "# question = input(\"Stel een vraag over een BN'er\\n\")\n",
        "# hij doet er wel een paar seconde over\n",
        "\n",
        "for question in question_list2:\n",
        "  QA(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx7WWl3tFspg",
        "outputId": "9c296ff4-d54b-4b51-b00d-b73448173ff5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++  {'Jan', 'volger', 'hebben', 'volgers', 'heeft'}\n",
            "Hoeveel volgers heeft Jan Smit? \t Niks gevonden\n",
            "+++  {'oud', 'Mark'}\n",
            "Hoe oud is Mark Rutte? \t Niks gevonden\n",
            "+++  {'hebben', 'onderscheiding', 'onderscheidingen', 'Froukje', 'heeft'}\n",
            "Hoeveel onderscheidingen heeft Froukje? \t Niks gevonden\n"
          ]
        }
      ]
    }
  ]
}